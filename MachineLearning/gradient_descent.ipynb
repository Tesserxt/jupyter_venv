{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64df2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63743889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_descent:\n",
    "# for linear regression(single col only) - loss_func: mse\n",
    "\n",
    "\tdef __init__(self, epochs, learning_rate):\n",
    "\t\tself.m = 100\n",
    "\t\tself.b = -120\n",
    "\t\tself.epochs = epochs\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\n",
    "\tdef fit(self, x, y):\n",
    "\t\tfor i in range(self.epochs) :\n",
    "\t\t\tdelta_b = -2 * np.sum( y - self.m * x.ravel() - self.b)\n",
    "\t\t\tdelta_m = -2 * np.sum((y - self.m * x.ravel() - self.b) * x.ravel())\n",
    "\n",
    "\t\t\tself.b = self.b - (self.learning_rate * delta_b)\n",
    "\t\t\tself.m = self.m - (self.learning_rate * delta_m)\n",
    "\n",
    "\t\tprint(f\"my_gradient_descent_LR: b = {self.b}, m = {self.m}\")\n",
    "\n",
    "\tdef predict(self, x):\n",
    "\t\treturn self.m * x + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDRegressor:\n",
    "# calculates coef_der, intercept_der on all rows in each epoch\n",
    "\n",
    "\tdef __init__(self,learning_rate=0.01,epochs=100):\n",
    "\n",
    "\t\tself.coef_ = None\n",
    "\t\tself.intercept_ = None\n",
    "\t\tself.lr = learning_rate\n",
    "\t\tself.epochs = epochs\n",
    "\n",
    "\tdef fit(self,X_train,y_train):\n",
    "\t\t# init your coefs\n",
    "\t\tself.intercept_ = 0\n",
    "\t\tself.coef_ = np.ones(X_train.shape[1])\n",
    "\n",
    "\t\tfor i in range(self.epochs):\n",
    "\t\t\t# update all the coef and the intercept\n",
    "\t\t\t# vectorization\n",
    "\t\t\ty_hat = np.dot(X_train,self.coef_) + self.intercept_\n",
    "\n",
    "\t\t\tintercept_der = -2 * np.mean(y_train - y_hat)\n",
    "\t\t\tself.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "\t\t\tcoef_der = -2 * np.dot((y_train - y_hat),X_train)/X_train.shape[0]\n",
    "\t\t\tself.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "\n",
    "\t\tprint(self.intercept_,self.coef_)\n",
    "\n",
    "\tdef predict(self,X_test):\n",
    "\t\treturn np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor:\n",
    "# In each epoch, calculates coef_der, intercept_der of single random row at a time for ntimes. where, ntimes = no of rows\n",
    "\n",
    "\tdef __init__(self,learning_rate=0.01,epochs=100):\n",
    "\n",
    "\t\tself.coef_ = None\n",
    "\t\tself.intercept_ = None\n",
    "\t\tself.lr = learning_rate\n",
    "\t\tself.epochs = epochs\n",
    "\n",
    "\tdef fit(self,X_train,y_train):\n",
    "\t\t# init your coefs\n",
    "\t\tself.intercept_ = 0\n",
    "\t\tself.coef_ = np.ones(X_train.shape[1])\n",
    "\n",
    "\t\tfor i in range(self.epochs):\n",
    "\t\t\tfor j in range(X_train.shape[0]):\n",
    "\t\t\t\trow_no = np.random.randint(X_train.shape[0])\n",
    "\t\t\t\ty_hat = np.dot(X_train[row_no],self.coef_) + self.intercept_\n",
    "\t\t\t\t\n",
    "\t\t\t\tintercept_der = -2 * (y_train[row_no] - y_hat)\n",
    "\t\t\t\tself.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "\t\t\t\tcoef_der = -2 * np.dot((y_train[row_no] - y_hat),X_train[row_no])\n",
    "\t\t\t\tself.coef_ = self.coef_ - (self.lr * coef_der)\t\n",
    "\n",
    "\t   \n",
    "\n",
    "\tdef predict(self,X_test):\n",
    "\t\treturn np.dot(X_test,self.coef_) + self.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn ols LR: b = -2.2710144261783825, m = [28.12597332]\n",
      "sklearn LR_r2:  0.6345158782661012\n",
      "my_gradient_descent_LR: b = -2.271014426179438, m = 28.12597331513731\n",
      "my gradient_descent_r2:  0.6345158782660945\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "x, y = make_regression(\n",
    "\tn_samples=100, n_features=1, n_informative=1, n_targets=1, noise=20, random_state=13\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "print(f\"sklearn ols LR: b = {lr.intercept_}, m = {lr.coef_}\")\n",
    "y_pred = lr.predict(x_test)\n",
    "print(\"sklearn LR_r2: \", r2_score(y_test, y_pred))\n",
    "\n",
    "gd = gradient_descent(200, 0.001)\n",
    "gd.fit(x_train, y_train)\n",
    "yp = gd.predict(x_test)\n",
    "print(\"my gradient_descent_r2: \", r2_score(y_test, yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn ols LR: b = 727.2678228247314, m = [406.59329087] and r2Score = r2\n",
      "my_gradient_descent_LR: b = -1.275167840696641e+167, m = -4.065615061638988e+168\n"
     ]
    }
   ],
   "source": [
    "ddf = pd.read_csv(\n",
    "\t\"/home/tesserxt/AllProjects/jupyter/campusx/content/insurance_data.csv\"\n",
    ")\n",
    "df = ddf[[\"bmi\", \"claim\"]]\n",
    "xy_train, xy_test = train_test_split(df, test_size=0.2, random_state=2)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(xy_train[\"bmi\"].to_frame(), xy_train[\"claim\"])\n",
    "y_pred = lr.predict(xy_test[\"bmi\"].to_frame())\n",
    "r2 = r2_score(xy_test.claim, y_pred)\n",
    "print(f\"sklearn ols LR: b = {lr.intercept_}, m = {lr.coef_} and r2Score = r2\")\n",
    "\n",
    "\n",
    "x_train, y_train = xy_train.values.T\n",
    "x_test, y_test = xy_test.values.T\n",
    "\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "gd = gradient_descent(50, 0.001)\n",
    "gd.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
